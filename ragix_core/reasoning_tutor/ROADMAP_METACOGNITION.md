# ROADMAP â€” Meta-Cognitive Architecture for LLM Reasoning

**Author:** Olivier Vitrac, PhD, HDR | olivier.vitrac@adservio.fr | Adservio
**Date:** 2025-12-23
**Status:** Post-Olympics Validation

---

## Executive Summary

Following the **LLM Reasoning Olympics 2025-12-23**, where 11 models competed across 6 benchmarks (66 total games), this roadmap defines the path from *measuring failure* to *mitigating it in real-time*.

### Key Findings from Olympics

| Finding | Evidence | Impact |
|---------|----------|--------|
| **Complexity Wall** | Most models fail B03-B05 | Need meta-cognitive intervention |
| **Wall Breaker** | deepseek-r1:14b achieved 6/6 (100%) | Proves wall is passable with right approach |
| **David vs Goliath** | granite3.1-moe:3b (3B) beats 14B models | Size â‰  Performance |
| **Metric Bias** | llama3.2:3b: +4490 pts but 1/6 wins | Activity â‰  Achievement |
| **Card Effectiveness** | High card usage correlates with wins | "Know when to ask for help" |

### Roadmap Phases

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      META-COGNITIVE ARCHITECTURE ROADMAP                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Phase   â”‚ Component              â”‚ Status    â”‚ Priority â”‚ Target          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  R1      â”‚ FailureDetector        â”‚ âœ“ DONE    â”‚ â€”        â”‚ v0.61           â”‚
â”‚  R2      â”‚ Meta-Cards             â”‚ DESIGN    â”‚ P1       â”‚ v0.62           â”‚
â”‚  R3      â”‚ Justification Protocol â”‚ DESIGN    â”‚ P0       â”‚ v0.62           â”‚
â”‚  R4      â”‚ Fat-LLM Generation     â”‚ PLANNED   â”‚ P2       â”‚ v0.63           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## R1: FailureDetector â€” âœ“ COMPLETE

**Status:** Implemented and validated in Olympics
**Files:** `failure_detector.py`, integrated into `scored_mode.py`

### Capabilities

| Detection Type | Clinical Name | Pattern |
|----------------|---------------|---------|
| `REPETITION_LOOP` | Perseveration (Syntactic Aphasia) | Same command â‰¥3Ã— |
| `CIRCULAR_PATTERN` | Disorientation (Strategic Confusion) | Aâ†’Bâ†’Câ†’A cycle |
| `EXPLICIT_ERROR` | Agnosia (Error Recognition Failure) | â‰¥3 consecutive errors |
| `PROGRESS_STALL` | â€” | No PCG growth for â‰¥4 turns |
| `EXHAUSTION` | â€” | Turn limit approached |

### Validation Results

```
Model                   â”‚ Failures â”‚ Wins â”‚ Correlation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deepseek-r1:14b         â”‚    0     â”‚ 6/6  â”‚ Perfect
granite3.1-moe:3b       â”‚    4     â”‚ 3/6  â”‚ Low failures = Success
phi3:latest             â”‚   26     â”‚ 1/6  â”‚ High failures = Failure
```

**Conclusion:** FailureDetector is a **valid quality signal** â€” strong inverse correlation between failure rate and success.

---

## R2: Meta-Cards â€” Strategic Interventions

**Status:** DESIGN
**Priority:** P1
**Target:** v0.62

### Problem Statement

The **Complexity Wall** (B03-B05) blocks most models. Current "help cards" are:
- Generic (same card for all failures)
- Static (don't adapt to failure type)
- Reactive (offered only after multiple failures)

### Proposed Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           META-CARD TAXONOMY                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Card Type           â”‚ Trigger               â”‚ Strategy                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ESCAPE_LOOP         â”‚ REPETITION_LOOP       â”‚ "Try alternative approach"   â”‚
â”‚  COMPASS             â”‚ CIRCULAR_PATTERN      â”‚ "Enumerate all options"      â”‚
â”‚  ERROR_ANALYSIS      â”‚ EXPLICIT_ERROR        â”‚ "Parse error message"        â”‚
â”‚  PROGRESS_BOOST      â”‚ PROGRESS_STALL        â”‚ "Decompose into sub-goals"   â”‚
â”‚  STRATEGIC_RESET     â”‚ EXHAUSTION            â”‚ "Summarize progress, pivot"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Card Content Structure

```python
@dataclass
class MetaCard:
    card_type: str           # e.g., "ESCAPE_LOOP"
    trigger: FailureType     # Automatic matching
    instruction: str         # What to do
    example: str             # Concrete example
    anti_pattern: str        # What NOT to do
    pcg_hint: Optional[str]  # Relevant PCG evidence
```

### Integration Points

1. **FailureDetector â†’ MetaCardSelector**: On failure detection, select appropriate card
2. **MetaCardSelector â†’ GameLoop**: Inject card into next prompt
3. **GameLoop â†’ Logger**: Track card usage and effectiveness

### Success Metrics

- **Card Rescue Rate**: % of failures rescued by meta-cards
- **Wall Penetration**: % of models passing B03-B05 with meta-cards
- **Card Efficiency**: Success per card type

---

## R3: Justification Protocol â€” Fix the Metric Bias

**Status:** DESIGN
**Priority:** P0 (HIGHEST)
**Target:** v0.62

### Problem Statement

**llama3.2:3b anomaly:**
- +4490 points (highest total)
- 1/6 wins (near-worst)
- Diagnosis: "Verbose Confabulation" â€” looks busy, accomplishes little

Current scoring rewards *activity* not *achievement*:
- Each command can earn points
- Goal achievement is binary (win/lose)
- No penalty for pointless actions

### Proposed Solution: Mandatory Justification

Before each action, require a structured justification:

```python
@dataclass
class JustifiedAction:
    action: str               # The command/tool call
    hypothesis: str           # "I expect this to..."
    expected_evidence: str    # "This should reveal..."
    goal_proximity: str       # "This advances goal by..."
    confidence: float         # 0.0-1.0
```

### Scoring Reform

```
NEW_SCORE = BASE_SCORE Ã— JUSTIFICATION_QUALITY Ã— GOAL_PROXIMITY

Where:
- BASE_SCORE: Points from action outcome
- JUSTIFICATION_QUALITY:
    - 1.0: Hypothesis confirmed
    - 0.5: Hypothesis partially relevant
    - 0.0: No justification or irrelevant
- GOAL_PROXIMITY:
    - 1.0: Direct goal progress
    - 0.5: Indirect/setup action
    - 0.0: Tangential/distraction
```

### Expected Impact

| Model | Old Score | New Score (est.) | Change |
|-------|-----------|------------------|--------|
| deepseek-r1:14b | +1075 | +1075 | â€” (already justified) |
| llama3.2:3b | +4490 | ~+500 | -89% (confabulation penalized) |
| granite3.1-moe:3b | +1350 | +1200 | -11% (slight adjustment) |

### Implementation Steps

1. Add `JustifiedAction` dataclass
2. Modify prompt template to require justification
3. Add justification parser to response handler
4. Update scoring function with multipliers
5. Log justification quality for analysis

---

## R4: Fat-LLM Card Generation â€” Scalable Knowledge

**Status:** PLANNED
**Priority:** P2
**Target:** v0.63

### Problem Statement

Current cards are:
- Hand-crafted (doesn't scale)
- Generic (not problem-specific)
- Limited (fixed set)

**Solution:** Use a "Fat-LLM" (larger model like Claude/GPT-4) to generate problem-specific cards that smaller models can use.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FAT-LLM CARD GENERATION PIPELINE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚  Benchmark  â”‚â”€â”€â”€â”€â–¶â”‚  Fat-LLM         â”‚â”€â”€â”€â”€â–¶â”‚  Card Library       â”‚     â”‚
â”‚   â”‚  Problem    â”‚     â”‚  (Claude/GPT-4)  â”‚     â”‚  (JSON/YAML)        â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                              â”‚                          â”‚                   â”‚
â”‚                              â”‚ Generates                â”‚ Loaded by         â”‚
â”‚                              â–¼                          â–¼                   â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚                       â”‚  Meta-Cards      â”‚     â”‚  Small LLM          â”‚     â”‚
â”‚                       â”‚  - Strategies    â”‚â”€â”€â”€â”€â–¶â”‚  (granite, mistral) â”‚     â”‚
â”‚                       â”‚  - Hints         â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                       â”‚  - Examples      â”‚                                  â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Card Generation Prompt Template

```
You are an expert problem-solving tutor. Given this benchmark problem:

PROBLEM: {benchmark_description}
GOAL: {goal_state}
COMMON_FAILURES: {failure_patterns}

Generate 3-5 strategic hint cards that help a smaller LLM solve this problem.

For each card, provide:
1. TRIGGER: When to show this card (e.g., "after 2 failed file reads")
2. HINT: The strategic guidance (max 50 words)
3. ANTI-PATTERN: What NOT to do
4. EXAMPLE: A concrete example of the correct approach
```

### Expected Benefits

- **Scalability**: Generate cards for any new benchmark automatically
- **Problem-Specific**: Cards tailored to each problem's failure modes
- **Knowledge Transfer**: Fat-LLM reasoning distilled into actionable hints
- **Cost Efficiency**: Fat-LLM runs once; small LLMs benefit many times

---

## Timeline & Dependencies

```mermaid
gantt
    title Meta-Cognitive Architecture Roadmap
    dateFormat  YYYY-MM-DD
    section R1 FailureDetector
    Implementation           :done, r1a, 2025-12-20, 2025-12-23
    Olympics Validation      :done, r1b, 2025-12-23, 1d
    section R3 Justification
    Design                   :active, r3a, 2025-12-23, 3d
    Implementation           :r3b, after r3a, 5d
    Testing                  :r3c, after r3b, 3d
    section R2 Meta-Cards
    Design                   :r2a, 2025-12-24, 3d
    Implementation           :r2b, after r2a, 5d
    Integration              :r2c, after r2b r3c, 3d
    section R4 Fat-LLM
    Design                   :r4a, after r2c, 5d
    Implementation           :r4b, after r4a, 7d
```

**Critical Path:** R3 (Justification) must complete before R2 integration to fix metric bias.

---

## Success Criteria

### v0.62 Release Criteria

| Criterion | Threshold | Metric |
|-----------|-----------|--------|
| Metric Bias Fix | llama3.2:3b score â‰¤ granite score | New scoring system |
| Wall Penetration | â‰¥50% of models pass B03 | With meta-cards |
| Card Effectiveness | â‰¥30% rescue rate | Failures â†’ Success |

### v0.63 Release Criteria

| Criterion | Threshold | Metric |
|-----------|-----------|--------|
| Auto-Generated Cards | â‰¥3 cards per benchmark | Fat-LLM pipeline |
| Small LLM Improvement | â‰¥20% win rate increase | With generated cards |
| Card Quality | Human rating â‰¥4/5 | Expert review |

---

## References

### Internal Documents

- `README_GAME_NOTATION.md` â€” PGN-AI notation specification
- `OLYMPICS_2025-12-23.md` â€” Full competition results
- `failure_detector.py` â€” R1 implementation
- `olympics_features.csv` â€” Feature matrix for analysis

### Key Visualizations

- `pca_2d.png` â€” Feature space (PC1=52.6%, PC2=27.6%)
- `dendrogram.png` â€” Model behavioral clusters
- `failure_analysis.png` â€” Failure type breakdown
- `params_vs_score.png` â€” Size vs performance (r=-0.132)

---

## Conclusion

The **LLM Reasoning Olympics 2025-12-23** established that:

1. **Meta-cognitive detection works** â€” FailureDetector accurately predicts performance
2. **Small models can win** â€” With the right interventions (cards), 3B beats 14B
3. **Metrics need reform** â€” Activity without justification inflates scores
4. **Knowledge transfer scales** â€” Fat-LLM can generate cards for small LLMs

This roadmap moves RAGIX from **observation** (measuring failure) to **intervention** (mitigating failure), making local LLMs behave like disciplined software engineers.

---

*"The measure of intelligence is not whether you solve the puzzle, but how you navigate when lost."*

**Bons dÃ©veloppements!** ğŸ†
